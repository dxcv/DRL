{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-28T22:11:59.059202Z",
     "start_time": "2018-04-28T22:11:59.056226Z"
    }
   },
   "source": [
    "# Data Processing \n",
    "\n",
    "This notebook presents the pre-processing of the S&P 500 data used to produce the input tensors of the neural network. <br>\n",
    "For each stock, the input is a raw time series of the prices (High, Low, Open, Close). Note that we include both Close from previous period (t-1) and Open from current period (t) as they differe for daily stock market data. However, even for continuously traded assets such as Crypto there are discrepancies and it cannot be assumed to be equal based on data.\n",
    "\n",
    "The features columns correspond to:\n",
    "- Close(t-1)/Open(t-1)\n",
    "- High(t-1)/Open(t-1)\n",
    "- Low(t-1)/Open(t-1)\n",
    "- Open(t)/Open(t-1)\n",
    "    \n",
    "<u>Remark:</u> We don't need to normalize the data since it's already of ratio of 2 prices closed to one.\n",
    "\n",
    "The shape corresponds to:\n",
    "- 4: Number of features\n",
    "- 5: Number of stocks \n",
    "- 1258: Number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 5/5 [00:00<00:00, 98.54it/s]\n There is 5 different assets. \n Following assets will be loaded ['AAPL', 'AXP', 'BA', 'CAT', 'CSCO']\n\n"
    }
   ],
   "source": [
    "# Specify Directory of Data (StocksD/StocksH/StocksM/CryptoD/CryptoH)\n",
    "data_dir = 'StocksD'\n",
    "directory = os.getcwd() + '/' + data_dir + '/'\n",
    "# Get list of all files\n",
    "stock_files = os.listdir(directory)\n",
    "stock_files.sort()\n",
    "# Remove hidden and unwanted files\n",
    "for file in stock_files: \n",
    "    if file[0] == '.': stock_files.remove(file)\n",
    "    if file[0] == '~': stock_files.remove(file)\n",
    "# Load only subset of assets\n",
    "selection = []    \n",
    "if selection: stock_files = [stock_files[i] for i in selection ]\n",
    "# Extract stock names only\n",
    "stock_tickers = [file.split('_')[0] for file in stock_files]\n",
    "# Check the history of stocks matches\n",
    "kept_stocks = list() ; not_kept_stocks = list()\n",
    "for s in tqdm(stock_files):\n",
    "    df = pd.read_csv(directory + s)\n",
    "    if data_dir == 'StocksD':   \n",
    "        input_n = 1259 # 5 years (252*5)\n",
    "        if len(df)>=input_n: kept_stocks.append(s)\n",
    "        else: not_kept_stocks.append(s)\n",
    "    elif data_dir == 'StocksH':\n",
    "        input_n = 1976  # 1/2 year (152*6.5*2)\n",
    "        if len(df)>=input_n: kept_stocks.append(s)\n",
    "        else: not_kept_stocks.append(s)\n",
    "    elif data_dir == 'StocksM':\n",
    "        input_n = 59280 # 1/2 year (152*6.5*60)\n",
    "        if len(df)>=input_n: kept_stocks.append(s)\n",
    "        else: not_kept_stocks.append(s)\n",
    "    elif data_dir == 'CryptoH':\n",
    "        input_n = 17520 # 1 year (365*24*2)\n",
    "        if len(df)>=input_n: kept_stocks.append(s)\n",
    "        else: not_kept_stocks.append(s)\n",
    "# Check if some stocks couldn't be loaded\n",
    "print('\\n There is {} different assets. \\n Following assets will be loaded {}'.format(len(stock_tickers),stock_tickers))\n",
    "if not_kept_stocks: print(' Error in reading following stocks {}'.format(not_kept_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 5/5 [00:00<00:00, 15.92it/s]\n Data have shape (4, 5, 1258)\n Number of features: 4\n Number of assets: 5\n Number of samples: 1259\n Input tensor saved!\n\n"
    }
   ],
   "source": [
    "# Read the stocks data\n",
    "list_open = list()\n",
    "list_close = list()\n",
    "list_high = list()\n",
    "list_low = list()\n",
    "\n",
    "for s in tqdm(kept_stocks):\n",
    "    data = pd.read_csv(directory + s).fillna('bfill').copy()\n",
    "    data = data[['open', 'close', 'high', 'low']]\n",
    "    data = data.tail(input_n)\n",
    "\n",
    "    list_open.append(data.open.values)\n",
    "    list_close.append(data.close.values)\n",
    "    list_high.append(data.high.values)\n",
    "    list_low.append(data.low.values)\n",
    "\n",
    "array_open = np.transpose(np.array(list_open))[:-1]\n",
    "array_open_of_the_day = np.transpose(np.array(list_open))[1:]\n",
    "array_close = np.transpose(np.array(list_close))[:-1]\n",
    "array_high = np.transpose(np.array(list_high))[:-1]\n",
    "array_low = np.transpose(np.array(list_low))[:-1]\n",
    "\n",
    "# Combine data together into one tensor\n",
    "X = np.transpose(np.array([array_close/array_open, \n",
    "                           array_high/array_open,\n",
    "                           array_low/array_open,\n",
    "                           array_open_of_the_day/array_open]), axes= (0,2,1))\n",
    "if False: X = np.transpose(np.array([array_high/array_open,\n",
    "                                     array_low/array_open,\n",
    "                                     array_open_of_the_day/array_open]), axes= (0,2,1))\n",
    "# Save dimensions of data\n",
    "input_f, input_m, imput_n = X.shape\n",
    "print('\\n Data have shape {}'.format(X.shape))\n",
    "print(' Number of features: {}'.format(input_f))\n",
    "print(' Number of assets: {}'.format(input_m))\n",
    "print(' Number of samples: {}'.format(input_n))\n",
    "np.save('./input.npy', X)\n",
    "print(' Input tensor saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['AAPL', 'AXP', 'BA', 'CAT', 'CSCO']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T22:20:34.439882Z",
     "start_time": "2018-07-04T22:20:34.422446Z"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}